# ParoleNet

ParoleNet is a multimodal model for predicting turn-taking in conversations. Its primary objective is to determine, at the end of a given sentence, whether the current speaker will continue speaking or yield the floor to their interlocutor. It takes as input the last 20 words of the sentence and the final two seconds of the audio recording, performing classification into two turn-taking classes.

üîç **Key Highlights:**
- Trained on a specific French-language dataset containing 16,400 sentences.
- Achieved promising results surpassing random initialization, indicating the model's ability to anticipate turn-taking.
- Statistical analysis suggests the model understands the relationship between input data and turn-taking prediction, rather than relying solely on frequency-based predictions.
- Demonstrates significant learning, validating the effectiveness of our approach.

# Table des mati√®res

- [ParoleNet](#parolenet)
- [Pr√©sentation du probl√®me et des donn√©es](#pr√©sentation-du-probl√®me-et-des-donn√©es)
        - [Figure 1 - Tableau du dataset.](#figure-1---tableau-du-dataset)
- [Pr√©sentation du mod√®le](#pr√©sentation-du-mod√®le)
        - [Figure 2 - Sch√©ma du mod√®le.](#figure-2---sch√©ma-du-mod√®le)
- [M√©trique et apprentissage](#m√©trique-et-apprentissage)
- [R√©sultats et discussion](#r√©sultats-et-discussion)
        - [Figure 3 - R√©sultats du mod√®le initialis√© au hasard.](#figure-3---r√©sultats-du-mod√®le-initialis√©-au-hasard)
        - [Figure 4 - R√©sultats du mod√®le √† la fin de l‚Äôapprentissage.](#figure-4---r√©sultats-du-mod√®le-√†-la-fin-de-lapprentissage)
- [Conclusion](#conclusion)

# ParoleNet

ParoleNet est un mod√®le multimodal de pr√©diction du tour de parole. Son objectif principal est de d√©terminer, √† la fin d‚Äôune phrase donn√©e, si la personne en cours d‚Äô√©locution continuera de parler ou c√©dera la parole √† son interlocuteur. Il prend en entr√©e les 20 derniers mots de la phrase ainsi que les deux derni√®res secondes de l'enregistrement audio et r√©alise la classification sur deux classes du tour de parole. ParoleNet a √©t√© entra√Æn√© sur un jeu de donn√©es sp√©cifique de la langue fran√ßaise contenant 16400 phrases. Nous avons observ√© des r√©sultats encourageants, o√π le mod√®le a appris √† anticiper le tour de parole avec une performance sup√©rieure √† un mod√®le initialis√© au hasard. L‚Äôanalyse des r√©sultats statistiques sugg√®re que le mod√®le est capable de comprendre un lien entre les donn√©es d‚Äôentr√©e et la pr√©diction du tour de parole, et non uniquement une pr√©diction statistique sur la fr√©quence de chaque classe d√©corr√©l√©e des donn√©es d'entr√©es. Ces observations indiquent un apprentissage significatif du mod√®le, renfor√ßant ainsi la validit√© de notre approche.

# Pr√©sentation du probl√®me et des donn√©es

L‚Äôobjet de la probl√©matique r√©side dans la pr√©diction de l‚Äôattribution de la parole au cours d‚Äôune discussion. Notre champ d‚Äô√©tude se restreindra √† un dialogue impliquant deux participants. Nous sommes ainsi confront√©s √† une probl√©matique de classification √† deux classes¬†: $0$ indiquant que la personne qui s‚Äôexprime continuera de parler apr√®s la fin de sa phrase, et $1$ signifiant qu‚Äôelle laissera la parole √† son interlocuteur. 

Les donn√©es que nous allons utiliser sont pr√©sent√©es de mani√®re d√©taill√©e dans le tableau en **Figure 1** ci-dessous. Les colonnes que nous allons utiliser sont : "stop" qui permet de r√©cup√©rer le timecode de la fin de la phrase, "text" qui permet de r√©cup√©rer ce qui vient d‚Äô√™tre prononc√© avant le timecode, "turn_after" qui indique si la personne va c√©der la parole ou non. 

Le dataloader a √©t√© con√ßu de mani√®re √† g√©n√©rer des exemples compos√©s de trois √©l√©ments distincts. Le premier √©l√©ment consiste en un texte form√© par les 20 derniers mots prononc√©s dans la phrase. En cas de phrase plus courte, un caract√®re de padding de l‚Äôencodeur textuel est ajout√© pour maintenir la structure. Le deuxi√®me √©l√©ment est constitu√© de la derni√®re seconde prononc√©e avant la fin de la phrase dans le fichier audio. Cette caract√©ristique vise √† repr√©senter le ton final de la phrase, que ce soit montant ou descendant, par exemple. Enfin, le dernier √©l√©ment correspond au label, √† savoir la valeur de la classe, soit $0$ ou $1$ pour indiquer le tour de parole.

![Texte alternatif](images/dataset.png)
##### Figure 1 - Tableau du dataset.

# Pr√©sentation du mod√®le

Le mod√®le √©labor√© est expos√© dans la **Figure 2**. Il se compose d‚Äôune premi√®re phase d‚Äôencodage des donn√©es, utilisant Wave2Vec2 pour les donn√©es audio et Camembert pour les donn√©es textuelles. Chacun de ces composants fait appel √† un processeur d√©di√© pour le traitement pr√©liminaire des donn√©es avant leur encodage. Un processus de padding est appliqu√© entre les √©tapes de traitement et d‚Äôencodage afin d‚Äôassurer la coh√©rence du flux de donn√©es. Les encodeurs g√©n√®rent des tenseurs de features, qui sont ensuite aplatis avant d‚Äô√™tre concat√©n√©s en un unique tenseur unidimensionnel, conservant ainsi une taille constante.

![Texte alternatif](images/schema.png)
##### Figure 2 - Sch√©ma du mod√®le.

Apr√®s l‚Äôextraction du tenseur, le mod√®le le transmet √† une cascade de couche dense, de fonction d‚Äôactivation ReLU et de dropout de 10%. Sur la sortie est appliqu√©e un softmax, ce processus repr√©sente ainsi une pr√©diction exprim√©e sous forme de probabilit√© pour les deux classes.

# M√©trique et apprentissage

Dans le cadre de la r√©solution de notre probl√®me de classification, il semble judicieux d‚Äôenvisager l‚Äôutilisation d‚Äôune fonction de perte de cross entropie. Les tests que nous avons effectu√©s montrent que le mod√®le a tendance √† rapidement converger vers la classification d‚Äôune seule classe, ind√©pendamment de l‚Äôexemple pr√©sent√©, en l‚Äôoccurrence la classe $0$. En effet, dans notre jeu de donn√©es, la classe $0$ repr√©sente 82% des exemples, tandis que la classe $1$ ne constitue que 18%. Par cons√©quent, le mod√®le r√©alise que pour maximiser sa pr√©cision, la m√©thode la plus simple est de pr√©dire syst√©matiquement la classe $0$, obtenant ainsi une pr√©cision de 82%, ce qui entrave la progression de l‚Äôapprentissage. Il est donc logique de consid√©rer l‚Äôutilisation de m√©triques prenant en compte les faux positifs, telles que le rappel, et pour englober ces aspects, le $F_1$ score. 

Dans le calcul de la pr√©cision et du rappel, nous avons recouru aux valeurs de probabilit√©s attribu√©es pour d√©terminer les vrais positifs, les faux positifs et les faux n√©gatifs. Plus pr√©cis√©ment, si le mod√®le attribue une probabilit√© de $0.4$ √† la classe $0$ et, par cons√©quent, de $0.6$ √† la classe $1$ pour un exemple donn√©, ces valeurs seront respectivement compt√©es comme $0.6$ en vrais positifs pour le score de la classe $1$. Ce m√™me principe s‚Äôapplique aux faux positifs et aux faux n√©gatifs. Ainsi, nous calculons le score $F_1$ pour la classification de chacune des deux classes. Et nous en faisons la moyenne pond√©r√©e par un poids qui d√©pend de la fr√©quence de chaque classe dans le batch. La fonction de perte est l'oppos√© du logarithme de ce $F_1$ score pond√©r√©.

# R√©sultats et discussion

Nous avons entrain√© le mod√®le sur le jeu de donn√©e pr√©sent√© en section 2. Voici donc les r√©sultats obtenus en **Figure 3** et **4**, ici en tenant compte de la pr√©diction par argmax :

| Classe      | Precision   | Rappel      | $F_1$       |
|-------------|-------------|-------------|-------------|
| 0           | 82.81       | 100.00      | 90.60       |
| 1           | 0.00        | 0.00        | 0.00        |

##### Figure 3 - R√©sultats du mod√®le initialis√© au hasard. 

| Classe      | Precision   | Rappel      | $F_1$       |
|-------------|-------------|-------------|-------------|
| 0           | 85.66       | 75.40       | 80.21       |
| 1           | 32.14       | 48.00       | 38.50       |

##### Figure 4 - R√©sultats du mod√®le √† la fin de l‚Äôapprentissage.

Le $F_1$ score pond√©r√© √©volue de 13 √† 42. On remarque que le mod√®le ne renvoie plus seulement une classe, mais bien une pr√©diction qui varie entre les deux classes. Ici, le mod√®le a bien appris puisqu‚Äôil fait mieux qu‚Äôun mod√®le initialis√© au hasard. Pour autant, il est possible d‚Äôenvisager que le mod√®le apprend simplement √† renvoyer al√©atoirement une classe avec une certaine probabilit√© pond√©r√©e pas la pr√©sence de 0 et de 1 dans le corpus d‚Äôentrainement, et donc que la sortie est d√©corr√©l√©e des entr√©es. Cependant, si c‚Äô√©tait le cas, on aurait des r√©sultats de pr√©cision proche de 82% pour la classe 0 et 18% pour la classe 1, ce qui n‚Äôest pas le cas. On remarque m√™me une am√©lioration au cours des it√©rations d‚Äôepochs ce qui confirme que le mod√®le a bien appris un lien entre les donn√©es d‚Äôentr√©e et la pr√©diction du tour de parole.

# Conclusion

En conclusion, notre √©tude sur la pr√©diction de l‚Äôattribution de la parole dans un dialogue √† deux participants a r√©v√©l√© des r√©sultats prometteurs, d√©montrant la capacit√© du mod√®le √† anticiper le tour de parole avec une performance sup√©rieure √† un mod√®le initialis√© au hasard. L‚Äôanalyse approfondie des r√©sultats sugg√®re une compr√©hension significative du lien entre les donn√©es d‚Äôentr√©e et la pr√©diction du tour de parole. Cependant, malgr√© ces avanc√©es, des perspectives d‚Äôam√©lioration subsistent. Il est crucial d‚Äôexplorer davantage les m√©canismes internes du mod√®le pour garantir que l‚Äôapprentissage ne se limite pas √† une simple corr√©lation statistique. Nous sommes confiants dans la solidit√© de la m√©trique qui a √©t√© utilis√©e, mais elle doit √™tre explor√©e d‚Äôavantage.
